{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from torchtext) (2.31.0)\n",
      "Collecting torch==2.2.1 (from torchtext)\n",
      "  Downloading torch-2.2.1-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from torchtext) (1.26.3)\n",
      "Collecting torchdata==0.7.1 (from torchtext)\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch==2.2.1->torchtext) (2023.12.2)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/homebrew/lib/python3.11/site-packages (from torchdata==0.7.1->torchtext) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->torchtext) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch==2.2.1->torchtext) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch==2.2.1->torchtext) (1.3.0)\n",
      "Downloading torchtext-0.17.1-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.1-cp311-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-macosx_11_0_arm64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torch, torchdata, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "Successfully installed torch-2.2.1 torchdata-0.7.1 torchtext-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from typing import Iterable, List\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, src_file, trg_file=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.src_file_path = os.path.join(self.data_dir, src_file)\n",
    "        self.trg_file_path = os.path.join(self.data_dir, trg_file) if trg_file else None\n",
    "\n",
    "        with open(self.src_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            self.src_lines = file.readlines()[:50]\n",
    "        self.src_lines = [line.rstrip() for line in self.src_lines]\n",
    "\n",
    "        if self.trg_file_path:\n",
    "            with open(self.trg_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                self.trg_lines = file.readlines()[:50]\n",
    "            self.trg_lines = [line.rstrip() for line in self.trg_lines]\n",
    "            assert len(self.src_lines) == len(self.trg_lines), \"Number of source and target lines must be the same.\"\n",
    "        else:\n",
    "            self.trg_lines = [None] * len(self.src_lines)\n",
    "        \n",
    "        self.texts = {SRC_LANGUAGE: self.src_lines, TGT_LANGUAGE: self.trg_lines}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.trg_file_path:\n",
    "            src, tgt = self.src_lines[idx], self.trg_lines[idx]\n",
    "            return src, tgt\n",
    "        else:\n",
    "            return self.src_lines[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer(None, language='de')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer(None, language='en')\n",
    "VOCAB_FILE = 'vocab.pth'\n",
    "\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "vocab_transform = {}\n",
    "\n",
    "def yielding(src: List[str], lang):\n",
    "   for s in src:\n",
    "      token_s = token_transform[lang](s)\n",
    "      for word in token_s:\n",
    "         yield word\n",
    "\n",
    "if os.path.isfile(VOCAB_FILE):\n",
    "  vocab_transform = torch.load(VOCAB_FILE)\n",
    "else:\n",
    "  for language in [\"de\", \"en\"]:\n",
    "      your_dataset = MyDataset(data_dir=\"data\", src_file=\"train.de-en.de\", trg_file=\"train.de-en.en\")\n",
    "      vocab_transform[language] = build_vocab_from_iterator([yielding(your_dataset.texts[language], language)],\n",
    "                                                            min_freq=1,\n",
    "                                                            specials=special_symbols,\n",
    "                                                            special_first=True)\n",
    "\n",
    "  for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "  torch.save(vocab_transform, VOCAB_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123554 56326\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_transform['de']), len(vocab_transform['en']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "class MyTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, dim_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(dim_ff, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src2 = self.norm1(src)\n",
    "        src = src + self.dropout(self.self_attn(src2, src2, src2, attn_mask=src_mask)[0])\n",
    "        src2 = self.norm2(src)\n",
    "        src = src + self.dropout(self.dropout(self.linear2(self.relu(self.linear1(src2)))))\n",
    "        return src\n",
    "\n",
    "class MyTransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int, dim_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(dim_ff, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor = None, memory_mask: Tensor = None) -> Tensor:\n",
    "        tgt2 = self.norm1(tgt)\n",
    "        tgt = tgt + self.dropout(self.self_attn(tgt2, tgt2, tgt2, attn_mask=tgt_mask)[0])\n",
    "        tgt2 = self.norm2(tgt)\n",
    "        tgt = tgt + self.dropout(self.multihead_attn(tgt2, memory, memory, key_padding_mask=memory_mask)[0])\n",
    "        tgt2 = self.norm3(tgt)\n",
    "        tgt = tgt + self.dropout(self.linear2(self.relu(self.linear1(tgt2))))\n",
    "        return tgt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransformerEncoder(nn.ModuleList):\n",
    "    def __init__(self, encoder_layers, d_model):\n",
    "        super().__init__(encoder_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.layers = encoder_layers\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "        src = self.norm(src)\n",
    "        return src\n",
    "\n",
    "class MyTransformerDecoder(nn.ModuleList):\n",
    "    def __init__(self, decoder_layers, d_model):\n",
    "        super().__init__(decoder_layers)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.layers = decoder_layers\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None,):\n",
    "        for layer in self.layers:\n",
    "            tgt = layer(tgt, memory, tgt_mask, memory_mask)\n",
    "        tgt = self.norm(tgt)\n",
    "        return tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        embedded_tokens = self.embedding(tokens.long())\n",
    "        scaled_embeddings = embedded_tokens * math.sqrt(self.emb_size)\n",
    "        return scaled_embeddings\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layers = [MyTransformerEncoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
    "                  for _ in range(num_encoder_layers)]\n",
    "        self.encoder = MyTransformerEncoder(encoder_layers, emb_size)\n",
    "\n",
    "        decoder_layers = [MyTransformerDecoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
    "                        for _ in range(num_decoder_layers)]\n",
    "        self.decoder = MyTransformerDecoder(decoder_layers, emb_size)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.encoder(src_emb, src_mask)\n",
    "        outs = self.decoder(tgt_emb, memory, tgt_mask, src_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, 0.0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    \n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    src_batch = []\n",
    "    for src_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    return src_batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1, ignore_index=-100):\n",
    "        \"\"\"\n",
    "        :param smoothing: The smoothing factor, with 0 representing no smoothing (standard cross-entropy).\n",
    "        :param ignore_index: Specifies a target value that is ignored and does not contribute to the input gradient.\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        :param logits: Logits output from the model (before softmax).\n",
    "        :param target: Target labels.\n",
    "        \"\"\"\n",
    "        c = logits.size(1)\n",
    "        log_preds = F.log_softmax(logits, dim=1)\n",
    "\n",
    "        # Create smoothed label vector\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(log_preds)\n",
    "            true_dist.fill_(self.smoothing / (c - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)\n",
    "\n",
    "            # Apply ignore_index\n",
    "            ignore = target == self.ignore_index\n",
    "            true_dist[ignore] = 0\n",
    "\n",
    "        # Mask out ignored indices from loss\n",
    "        mask = torch.nonzero(ignore, as_tuple=False).squeeze()  # Find indices of ignore_index\n",
    "        if mask.numel() > 0:\n",
    "            log_preds = log_preds.index_fill(0, mask, 0.0)\n",
    "            true_dist = true_dist.index_fill(0, mask, 0.0)\n",
    "\n",
    "        return torch.mean(torch.sum(-true_dist * log_preds, dim=1))\n",
    "    \n",
    "loss_fn = LabelSmoothingLoss(smoothing=0.1, ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# class LabelSmoothingLoss(torch.nn.Module):\n",
    "#     def __init__(self, classes, smoothing=0.0, ignore_index=None, dim=-1):\n",
    "#         super(LabelSmoothingLoss, self).__init__()\n",
    "#         self.confidence = 1.0 - smoothing\n",
    "#         self.smoothing = smoothing\n",
    "#         self.classes = classes\n",
    "#         self.ignore_index = ignore_index\n",
    "#         self.dim = dim\n",
    "\n",
    "#     def forward(self, pred, target):\n",
    "#         with torch.no_grad():\n",
    "#             target = target.clone()\n",
    "#             if self.ignore_index is not None:\n",
    "#                 target[target == self.ignore_index] = 0\n",
    "#             target = torch.zeros_like(pred).scatter(self.dim, target.unsqueeze(self.dim), 1.0)\n",
    "#             target = target * self.confidence + (1 - target) * self.smoothing / (self.classes - 1)\n",
    "#         return torch.sum(-target * F.log_softmax(pred, dim=self.dim), dim=self.dim)\n",
    "\n",
    "# loss_fn = LabelSmoothingLoss(classes=56326, smoothing=0.1, ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from torch import tensor\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_losses(train_losses: List[float], val_losses: List[float]):\n",
    "    \"\"\"\n",
    "    Plot loss and perplexity of train and validation samples\n",
    "    :param train_losses: list of train losses at each epoch\n",
    "    :param val_losses: list of validation losses at each epoch\n",
    "    \"\"\"\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
    "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
    "    axs[0].set_ylabel(\"loss\")\n",
    "\n",
    "    \"\"\"\n",
    "    YOUR CODE HERE (⊃｡•́‿•̀｡)⊃━✿✿✿✿✿✿\n",
    "    Calculate train and validation perplexities given lists of losses\n",
    "    \"\"\"\n",
    "    train_perplexities = [math.exp(loss) for loss in train_losses]\n",
    "    val_perplexities = [math.exp(loss) for loss in val_losses]\n",
    "\n",
    "    axs[1].plot(\n",
    "        range(1, len(train_perplexities) + 1), train_perplexities, label=\"train\"\n",
    "    )\n",
    "    axs[1].plot(range(1, len(val_perplexities) + 1), val_perplexities, label=\"val\")\n",
    "    axs[1].set_ylabel(\"perplexity\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def training_epoch(model, optimizer, loader, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for src, trg in tqdm(loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        src, tgt = src.to(device), trg.to(device)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        \n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        output = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask)\n",
    "        # print('output', output.shape)\n",
    "        # print('tgt', tgt_input.shape)\n",
    "        \n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for src, trg in tqdm(loader, desc=\"Training\"):\n",
    "        src, tgt = src.to(device), trg.to(device)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        output = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1)).mean()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, num_epochs, device, pad_id):\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    # criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = training_epoch(model, optimizer, train_loader, device)\n",
    "        val_loss = validation_epoch(model, val_loader, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        plot_losses(train_losses, val_losses)\n",
    "\n",
    "    print(f\"Training complete. Best validation loss: {min(val_losses)}\")\n",
    "\n",
    "    return min(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDYAAAFzCAYAAADFfok0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdxElEQVR4nO3deXxU1cH/8e/MJJkQQhICZEHCIiAQIKwWBq0baFikorRVRIMV0fILVkAspg8qSyXUDfWRgloV+1RKixVtQcGAEisEiiwa0KJQNKGSRBESwpJt7u+PIcNMMpONkJlJPu/X674yc+65954zNzLHb86912QYhiEAAAAAAIAAZPZ1AwAAAAAAABqKYAMAAAAAAAQsgg0AAAAAABCwCDYAAAAAAEDAItgAAAAAAAABi2ADAAAAAAAELIINAAAAAAAQsAg2AAAAAABAwArydQOamt1u17fffqs2bdrIZDL5ujkAAPgVwzB08uRJdezYUWYzf/+42BiXAADgXV3HJS0u2Pj222+VkJDg62YAAODXcnNz1alTJ183o9ljXAIAQO1qG5e0uGCjTZs2khwfTEREhI9bAwCAfykqKlJCQoLz+xIXF+MSAAC8q+u4pMUFG5XTPCMiIhhAAADgBZdFNA3GJQAA1K62cQkXzwIAAAAAgIBFsAEAAAAAAAIWwQYAAGjxlixZIpPJpJkzZzrLzp49q9TUVLVr107h4eGaOHGi8vPz3bbLycnRuHHjFBYWppiYGD300EMqLy9v4tYDANCyEWwAAIAWbefOnXrxxReVlJTkVj5r1iz94x//0Jo1a5SZmalvv/1Wt9xyi3N9RUWFxo0bp9LSUm3btk2vv/66Vq5cqUcffbSpuwAAQIvm82Djv//9r+644w61a9dOrVq1Uv/+/fXJJ5/UuM2WLVs0ePBgWa1W9ejRQytXrmyaxgIAgGaluLhYkydP1ssvv6y2bds6ywsLC/XKK6/omWee0XXXXachQ4botdde07Zt27R9+3ZJ0vvvv6/PP/9cf/rTnzRw4ECNGTNGixYt0rJly1RaWuqrLgEA0OL4NNg4fvy4rrjiCgUHB+u9997T559/rqefftptYFHV4cOHNW7cOF177bXau3evZs6cqXvuuUcbN25swpYDAIDmIDU1VePGjdOoUaPcynft2qWysjK38t69e6tz587KysqSJGVlZal///6KjY111klOTlZRUZH279/v8XglJSUqKipyWwAAwIXx6eNef/e73ykhIUGvvfaas6xbt241brNixQp169ZNTz/9tCSpT58++vjjj7V06VIlJydf1PYCAIDmY/Xq1dq9e7d27txZbV1eXp5CQkIUFRXlVh4bG6u8vDxnHddQo3J95TpP0tPTtWDBgkZoPQAAqOTTGRt///vfNXToUP3sZz9TTEyMBg0apJdffrnGbbKysqr9VSU5Odn51xMAAIDa5Obm6oEHHtAbb7yh0NDQJjtuWlqaCgsLnUtubm6THRsAgObKp8HGf/7zHy1fvlw9e/bUxo0bNX36dP3qV7/S66+/7nUbb38dKSoq0pkzZ6rVZ8onAACoateuXSooKNDgwYMVFBSkoKAgZWZm6vnnn1dQUJBiY2NVWlqqEydOuG2Xn5+vuLg4SVJcXFy1p6RUvq+sU5XValVERITbAgAALoxPL0Wx2+0aOnSoFi9eLEkaNGiQ9u3bpxUrVmjKlCmNcowmmfL5xTrHzyCrZAmRgkKloBDJYnUpc/1plcw+v28rAAAt1siRI5Wdne1W9otf/EK9e/fW3LlzlZCQoODgYG3evFkTJ06UJB04cEA5OTmy2WySJJvNpscff1wFBQWKiYmRJGVkZCgiIkKJiYlN26FKPxyWvt0ttY6RWneQwmOk0CjGHQCAZs2nwUZ8fHy1L/4+ffrob3/7m9dtvP11JCIiQq1atapWPy0tTbNnz3a+LyoqUkJCwgW2vIq1v5RKT9ZvG3Ow99DDNRTxuu5cgOJtndv2VoIWAABctGnTRv369XMra926tdq1a+csnzp1qmbPnq3o6GhFRETo/vvvl81m0/DhwyVJN9xwgxITE3XnnXfqiSeeUF5enubNm6fU1FRZrdYm75Mk6fBH0j9+5V5mDpLC2p8LOjo4flYu4THu71t3cIwZAAAIID4NNq644godOHDArezLL79Uly5dvG5js9n07rvvupVlZGQ4/3pSldVqvfiDi4TLpZJiqfysVFEqlZd4+Fnivo29TCotu7jtqo8ag5YaApG6hjAWa5WZLB6ClsrtLCEELQAAn1u6dKnMZrMmTpyokpISJScn6/e//71zvcVi0bp16zR9+nTZbDa1bt1aU6ZM0cKFC33X6FZtpS5XSKe+k4oLpLMnJHu5VJznWPJr3YMUGnku5IiRWrevHn64vre2kUymi90rAABqZDIMw/DVwXfu3KkRI0ZowYIF+vnPf65//etfmjZtml566SVNnjxZkmPGxX//+1/98Y9/lOR43Gu/fv2Umpqqu+++Wx988IF+9atfaf369XV6KkpRUZEiIyNVWFjYtNe1GobnsKO8tMrPsx7KqgYlZ2tY51rH2zoPQYu/8Ra0uIYt3oIWt5ksVYMWlyXIKlmCz4cpXtefC2HMFgZvAJo9n31PtlAX/fMuL5VOf38u6PjO8fNUgYf35+rYy+u3f4v1XNDR3uXylw7VZ4GEx0hh7RzfpQAA1FFdvyd9OmPj8ssv19q1a5WWlqaFCxeqW7duevbZZ52hhiQdPXpUOTk5zvfdunXT+vXrNWvWLD333HPq1KmT/vCHP/j/o15NpvP/Y+4P6hK0lJ/1Er64bFNtuwaGMBWl7u3ztxktkiTT+bDEGX6EnA8+LMH1CEvqu95TmesxQwhdAADVBYVIER0dS23sdscMj1PfnZ/xcep770FIabHj+70w17HUyuQIN9zCj6qzQlzeB1e/xBgAAE98OmPDF/hLlJ+qNWjxFKLUcZ3rfiuX8tIq70ukijLHNhVlgTGrpSpzcCOELcEewpsq6xsS0Fh8mqECqAe+J5tWQH/epafPBR2u4YeXMOT0MUn1HHKGhFeZ9eEtDOnguASHgB8Amp2AmLEBOPnbjBbJEbbYy2sIPmoLRuqyvrKsrmGLy/qq04XtZY6l7JRvPq+amMx1DFuCXQKSYPdtvK6vGqx4qVPr+mAGxQBQHyFhUkgXqa33e6M5VZRLZ344F3x8V/uskIoSx4yQ0mLp+OHa928OOhdyeLokJub8uvAYx41UuUEqADQrBBuANybTuf/xDZZCWvu6NdXZK2oJUypf1xa2eAtTGhC2uB7TlWE/d1nSWd98VnVVY/jhKWjxUrdeQUsNx3POnnFZbw4igAEQeCxBjlAhPKb2uoYhlZysEn7UEIacLXSE/SePOpa6CI1yuRGqtzDkXBASEs6/uwDg5wg2gEBltjiW4FBft6S6ytku9QpbqoQsbu+rvHab8VK1Tpn7MbytLy9RtWnRlXX9nVsIUjX88BS01GHWS11ntbi99rLPysuieLoRgIYwmaTQCMfSrnvt9ctLXIKO72sJQr6XjArHvUTOnpCOfVX7/oNCa7gkpsr7sGhukAoAPkCwAaDxuc528WcV5XUIUjyFLfUJWlwvOappfdUZMi4BTbV2B0gAY7J4CEWCvAclZm/hS9XyKjNYGhq8cCkS0DwEWaXISxxLbSpvkOoMP2oJQ8pOOWYb1vUGqSbz+Rukuj0et32Vy2LaOeoxGwQAGgXBBoCWyxLkWBTm65Z4ZxjnLjuqKWip8rq8lvV1ndXi3Ne5enZPQVDZ+ddGRZW2V0jlZxxLIDAHVwlE6hKi1BCgWEJc9ukpfPESytQlrOGSJKBhzGbHrIqwaEm9a69feqqWR+W6BCFnfnBcellZVheWEEfAEdbO0aZW0S7vXcpdfwaH8d8/AFRBsAEA/sxkCowARnK574tL8GEvqyFg8TJjxmOAUiVE8bRPr8fysr+qlyI5b8Drk0+v/lwDj6sflob/0tctApqfkNaOpW3X2utWlDue/uLt8bhus0K+l/N+VvW5N4jkuDTGLfA4t7SK9lweFs2jcwE0ewQbAIDG4c/3famqciaMvYagpKKGUMZr+FJDKFPtWPUMeapyLbcHShoDNGOWIKlNrGOpjWFIZacdQcjpH6r8dFnO/OBeXlHquDSm6L+Opa6Cw7yEHu0cj8r1NEvEn55UBwC1INgAALQ8rjNhAuEvma6Pn/Y0eyWsna9bCKA+TKbzs0GiOtdtG8NwPP7WGXwcrx6EVAYkZ1zCEHu5I0QpPF23+4RUCmkjhXkJPdxmiLiU+/u9tQA0WwQbAAD4O7cb8vrh46cBXHwmk2Rt41jqcmmMdO7RuUW1zwypLKsMRAy7VHrSsZzIqXsbrZHV7wlS02Uzrdqeu9QSAC4M/5IAAAAAzZHJJIVGOpboS+u2jd0ulRR6CEB+8PL6mHTmuCTDsV1JoXT8cN3bGBrlYUaIp5uongtEWkXxSF0A1RBsAAAAAHAwmx0zKVq1ldp1r9s29grpbKH3S2M8zRI5e8Kx7dkTjuWHQ3VsoMnDfUFqCEPCoh0zSczm+n8WAAIGwQYAAACAhjNbXB6j27Nu21SUOwKNOochPzhmg8hwXDJz5gfp2Fd1O5bJXOWeIDVcJlP52F1rBGEIEEAINgAAAAA0LUuQ1Lq9Y6mrirLqN0etdnlMlUtmSk867hly+nvHUlcms+MymVZtz4UdbassVcuimB0C+BDBBgAAAAD/Zwmu+yN1K5WXVL85qsebqFbOEvne8RQZw35+ZkidL5ORHJfKRNUQgHgJSkIjuXcIcAEINgAAAAA0T0FWKSLesdRV2VnHZTJnjjuW0z+cf+1cXMvO1S0tluNSmXPl9XLuRq91CUFcw5LQSJ4sA4hgAwAAAADOCw6VguOkNnH126685HzI4TUEcQ1LztUtPSnJOH8j1fo8VUY695jdquFHLbNFQqMIRNCs8NsMAAAAABcqyFr/S2Ukx71DzpyoIQDxFJSckEqKHNs7H7P7df2Oa404d9lMHS+XqXzcriW4fscBmgDBBgAAAAD4iiVYCu/gWOqjoszxmN06XS5TGZQcP/d0GTmCkZIi6URO/Y4b0sb9hql1mSnSqq0UFFK/4wD1QLABAAAAAIHGElz/J8tI5x61W1iHS2WqlJ0997jd0pOOpbC+gUj4+UCkPjdWDbLW7zhokQg2AAAAAKClsARJrds5lvqwV1QJROo6U+SEHIFIsWMpzK3fcYNbuz9Wt1XUuUfxevrZ9vx7bqzaonCmAQAAAAA1M1scMyrCouu3nd3u8pSZE7WEIC5hydkTjsfulp1yLEVH6t/mkDZVgo9ID4FIWw8BSST3EgkwBBsAAAAAgIvDbG54IFJS5B6AnD4XeJw5UfPP0mLHPpyXzdRzlojkuHTGNfDwGIp4+cn9RJocwQYAAAAAwL+YzecvPVG3+m1beR8RZ9hxvPYw5My5+pVPm6m8dKYhM0WCw+oWgHj6yT1FGoRgAwAAAADQfDT0PiKSIxSpnClSl9khrsFI5RNnyk47lpPf1v/4Qa1qD0C8zR4JblX/4zUTBBsAAKDFWb58uZYvX66vv/5aktS3b189+uijGjNmjCTpmmuuUWZmpts29913n1asWOF8n5OTo+nTp+vDDz9UeHi4pkyZovT0dAUFMbwCgIBlCWrYpTPS+Rusnj1x7karJ+oRjpx76kz5GenkGenk0Qa03dqwWSKhUY5QxGSq/zH9BN+8AACgxenUqZOWLFminj17yjAMvf7667rpppu0Z88e9e3bV5I0bdo0LVy40LlNWFiY83VFRYXGjRunuLg4bdu2TUePHlVKSoqCg4O1ePHiJu8PAMAPNPQGq9L5e4rUa5bIifMhimGXKkqk4nzHUl+WkIYFIqGRUkhrn4ciBBsAAKDFGT9+vNv7xx9/XMuXL9f27dudwUZYWJji4uI8bv/+++/r888/16ZNmxQbG6uBAwdq0aJFmjt3rubPn6+QEG4cBwCoB9d7irSt57Z2u+MmqTUFHzWFI0aFVFEqnSpwLPVue7D75TF3rWvyy2IINgAAQItWUVGhNWvW6NSpU7LZbM7yN954Q3/6058UFxen8ePH65FHHnHO2sjKylL//v0VGxvrrJ+cnKzp06dr//79GjRoUJP3AwDQQpnNjmAhNFJSl/ptaxiOm6TWd5ZI5U97uWQvk05/71hMFikotJE6VncEGwAAoEXKzs6WzWbT2bNnFR4errVr1yoxMVGSdPvtt6tLly7q2LGjPvvsM82dO1cHDhzQW2+9JUnKy8tzCzUkOd/n5eV5PWZJSYlKSkqc74uKihq7WwAA1J3JJFnbOBYl1G9bw5BKT1V51O4pn1yWQrABAABapF69emnv3r0qLCzUm2++qSlTpigzM1OJiYm69957nfX69++v+Ph4jRw5UocOHVL37t0bfMz09HQtWLCgMZoPAIBvmUySNdyxRHbyaVPMPj06AACAj4SEhKhHjx4aMmSI0tPTNWDAAD333HMe6w4bNkySdPDgQUlSXFyc8vPdb85W+d7bfTkkKS0tTYWFhc4lNze3MboCAECLRrABAAAgyW63u10m4mrv3r2SpPj4eEmSzWZTdna2CgrO32QtIyNDERERzstZPLFarYqIiHBbAADAheFSFAAA0OKkpaVpzJgx6ty5s06ePKlVq1Zpy5Yt2rhxow4dOqRVq1Zp7NixateunT777DPNmjVLV111lZKSkiRJN9xwgxITE3XnnXfqiSeeUF5enubNm6fU1FRZrVYf9w4AgJaFYAMAALQ4BQUFSklJ0dGjRxUZGamkpCRt3LhR119/vXJzc7Vp0yY9++yzOnXqlBISEjRx4kTNmzfPub3FYtG6des0ffp02Ww2tW7dWlOmTNHChQt92CsAAFomk2EYhq8b0ZSKiooUGRmpwsJCpn8CAFAF35NNi88bAADv6vo96dN7bMyfP18mk8lt6d27t9f6K1eurFY/NLTpn5ELAAAAAAD8g88vRenbt682bdrkfB8UVHOTIiIidODAAed7kw+ekQsAAAAAAPyDz4ONoKCgGh+LVpXJZKpXfQAAAAAA0Hz5/HGvX331lTp27KhLL71UkydPVk5OTo31i4uL1aVLFyUkJOimm27S/v37a6xfUlKioqIitwUAAAAAADQPPg02hg0bppUrV2rDhg1avny5Dh8+rB//+Mc6efKkx/q9evXSq6++qnfeeUd/+tOfZLfbNWLECB05csTrMdLT0xUZGelcEhISLlZ3AAAAAABAE/Orp6KcOHFCXbp00TPPPKOpU6fWWr+srEx9+vTRpEmTtGjRIo91SkpKVFJS4nxfVFSkhIQE7j4OAIAHPKWjafF5AwDgXV2/J31+jw1XUVFRuuyyy3Tw4ME61Q8ODtagQYNqrG+1WmW1WhuriQAAAAAAwI/4/B4broqLi3Xo0CHFx8fXqX5FRYWys7PrXB8AAAAAADQvPg025syZo8zMTH399dfatm2bbr75ZlksFk2aNEmSlJKSorS0NGf9hQsX6v3339d//vMf7d69W3fccYe++eYb3XPPPb7qAgAAAAAA8CGfXopy5MgRTZo0SceOHVOHDh105ZVXavv27erQoYMkKScnR2bz+ezl+PHjmjZtmvLy8tS2bVsNGTJE27ZtU2Jioq+6AAAAAAAAfMivbh7aFLhJFwAA3vE92bT4vAEA8K6u35N+dY8NAAAAAACA+iDYAAAAAAAAAYtgAwAAAAAABCyCDQAAAAAAELAINgAAAAAAQMAi2AAAAAAAAAGLYAMAAAAAAAQsgg0AAAAAABCwCDYAAAAAAEDAItgAAAAAAAABi2ADAAAAAAAELIINAAAAAAAQsAg2AAAAAABAwCLYAAAAAAAAAYtgAwAAAAAABCyCDQAAAAAAELAINgAAQIuzfPlyJSUlKSIiQhEREbLZbHrvvfec68+ePavU1FS1a9dO4eHhmjhxovLz8932kZOTo3HjxiksLEwxMTF66KGHVF5e3tRdAQCgxSPYAAAALU6nTp20ZMkS7dq1S5988omuu+463XTTTdq/f78kadasWfrHP/6hNWvWKDMzU99++61uueUW5/YVFRUaN26cSktLtW3bNr3++utauXKlHn30UV91CQCAFstkGIbh60Y0paKiIkVGRqqwsFARERG+bg4AAH6lJX9PRkdH68knn9RPf/pTdejQQatWrdJPf/pTSdK///1v9enTR1lZWRo+fLjee+893Xjjjfr2228VGxsrSVqxYoXmzp2r7777TiEhIXU6Zkv+vAEAqE1dvyeZsQEAAFq0iooKrV69WqdOnZLNZtOuXbtUVlamUaNGOev07t1bnTt3VlZWliQpKytL/fv3d4YakpScnKyioiLnrA9PSkpKVFRU5LYAAIALQ7ABAABapOzsbIWHh8tqteqXv/yl1q5dq8TEROXl5SkkJERRUVFu9WNjY5WXlydJysvLcws1KtdXrvMmPT1dkZGRziUhIaFxOwUAQAtEsAEAAFqkXr16ae/evdqxY4emT5+uKVOm6PPPP7+ox0xLS1NhYaFzyc3NvajHAwCgJQjydQMAAAB8ISQkRD169JAkDRkyRDt37tRzzz2nW2+9VaWlpTpx4oTbrI38/HzFxcVJkuLi4vSvf/3LbX+VT02prOOJ1WqV1Wpt5J4AANCyMWMDAABAkt1uV0lJiYYMGaLg4GBt3rzZue7AgQPKycmRzWaTJNlsNmVnZ6ugoMBZJyMjQxEREUpMTGzytgMA0JIxYwMAALQ4aWlpGjNmjDp37qyTJ09q1apV2rJlizZu3KjIyEhNnTpVs2fPVnR0tCIiInT//ffLZrNp+PDhkqQbbrhBiYmJuvPOO/XEE08oLy9P8+bNU2pqKjMyAABoYgQbAACgxSkoKFBKSoqOHj2qyMhIJSUlaePGjbr++uslSUuXLpXZbNbEiRNVUlKi5ORk/f73v3dub7FYtG7dOk2fPl02m02tW7fWlClTtHDhQl91CQCAFstkGIbh60Y0JZ4XDwCAd3xPNi0+bwAAvKvr9yT32AAAAAAAAAGLYAMAAAAAAAQsgg0AAAAAABCwCDYAAAAAAEDAItgAAAAAAAABi2ADAAAAAAAELIINAAAAAAAQsAg2AAAAAABAwPJpsDF//nyZTCa3pXfv3jVus2bNGvXu3VuhoaHq37+/3n333SZqLQAAAAAA8Dc+n7HRt29fHT161Ll8/PHHXutu27ZNkyZN0tSpU7Vnzx5NmDBBEyZM0L59+5qwxQAAAAAAwF/4PNgICgpSXFycc2nfvr3Xus8995xGjx6thx56SH369NGiRYs0ePBgvfDCC03YYgAAAAAA4C98Hmx89dVX6tixoy699FJNnjxZOTk5XutmZWVp1KhRbmXJycnKysryuk1JSYmKiorcFgAAAAAA0Dz4NNgYNmyYVq5cqQ0bNmj58uU6fPiwfvzjH+vkyZMe6+fl5Sk2NtatLDY2Vnl5eV6PkZ6ersjISOeSkJDQqH0AAAAAAAC+49NgY8yYMfrZz36mpKQkJScn691339WJEyf017/+tdGOkZaWpsLCQueSm5vbaPsGAAAAAAC+FeTrBriKiorSZZddpoMHD3pcHxcXp/z8fLey/Px8xcXFed2n1WqV1Wpt1HYCAAAAAAD/4PN7bLgqLi7WoUOHFB8f73G9zWbT5s2b3coyMjJks9maonkAAAAAAMDP+DTYmDNnjjIzM/X1119r27Ztuvnmm2WxWDRp0iRJUkpKitLS0pz1H3jgAW3YsEFPP/20/v3vf2v+/Pn65JNPNGPGDF91AQAAAAAA+JBPL0U5cuSIJk2apGPHjqlDhw668sortX37dnXo0EGSlJOTI7P5fPYyYsQIrVq1SvPmzdNvfvMb9ezZU2+//bb69evnqy4AAAAAAAAfMhmGYfi6EU2pqKhIkZGRKiwsVEREhK+bAwCAX+F7smnxeQMA4F1dvyf96h4bAAAAAAAA9UGwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgIBFsAEAAAAAAAIWwQYAAAAAAAhYBBsAAKDFSU9P1+WXX642bdooJiZGEyZM0IEDB9zqXHPNNTKZTG7LL3/5S7c6OTk5GjdunMLCwhQTE6OHHnpI5eXlTdkVAABavCBfNwAAAKCpZWZmKjU1VZdffrnKy8v1m9/8RjfccIM+//xztW7d2llv2rRpWrhwofN9WFiY83VFRYXGjRunuLg4bdu2TUePHlVKSoqCg4O1ePHiJu0PAAAtGcEGAABocTZs2OD2fuXKlYqJidGuXbt01VVXOcvDwsIUFxfncR/vv/++Pv/8c23atEmxsbEaOHCgFi1apLlz52r+/PkKCQm5qH0AAAAOXIoCAABavMLCQklSdHS0W/kbb7yh9u3bq1+/fkpLS9Pp06ed67KystS/f3/FxsY6y5KTk1VUVKT9+/d7PE5JSYmKiorcFgAAcGGYsQEAAFo0u92umTNn6oorrlC/fv2c5bfffru6dOmijh076rPPPtPcuXN14MABvfXWW5KkvLw8t1BDkvN9Xl6ex2Olp6drwYIFF6knAAC0TAQbAAAgYLz22mu69dZb3e51caFSU1O1b98+ffzxx27l9957r/N1//79FR8fr5EjR+rQoUPq3r17g46Vlpam2bNnO98XFRUpISGhYQ0HAACSuBQFAAAEkIcfflhxcXGaOnWqtm3bdsH7mzFjhtatW6cPP/xQnTp1qrHusGHDJEkHDx6UJMXFxSk/P9+tTuV7b/flsFqtioiIcFsAAMCFIdgAAAAB47///a9ef/11ff/997rmmmvUu3dv/e53v/N66Yc3hmFoxowZWrt2rT744AN169at1m327t0rSYqPj5ck2Ww2ZWdnq6CgwFknIyNDERERSkxMrFd7AABAwxFsAACAgBEUFKSbb75Z77zzjnJzczVt2jS98cYb6ty5s37yk5/onXfekd1ur3U/qamp+tOf/qRVq1apTZs2ysvLU15ens6cOSNJOnTokBYtWqRdu3bp66+/1t///nelpKToqquuUlJSkiTphhtuUGJiou688059+umn2rhxo+bNm6fU1FRZrdaL+jkAAIDzCDYAAEBAio2N1ZVXXimbzSaz2azs7GxNmTJF3bt315YtW2rcdvny5SosLNQ111yj+Ph45/KXv/xFkhQSEqJNmzbphhtuUO/evfXggw9q4sSJ+sc//uHch8Vi0bp162SxWGSz2XTHHXcoJSVFCxcuvJjdBgAAVXDzUAAAEFDy8/P1f//3f3rttdf0n//8RxMmTNC6des0atQonTp1SgsXLtSUKVP0zTffeN2HYRg1HiMhIUGZmZm1tqVLly569913690HAADQeJixAQAAAsb48eOVkJCglStXatq0afrvf/+rP//5zxo1apQkqXXr1nrwwQeVm5vr45YCAICmwowNAAAQMGJiYpSZmSmbzea1TocOHXT48OEmbBUAAPAlgg0AQMAxDEPl5eWqqKjwdVMCUnBwsCwWi6+b0SBXX321Bg8eXK28tLRUq1evVkpKikwmk7p06eKD1gEAWhrGJBfGYrEoKChIJpPpgvZjMmq7yLSZKSoqUmRkpAoLC3l2PAAEoNLSUh09elSnT5/2dVMClslkUqdOnRQeHl5tnb9/T1osFh09elQxMTFu5ceOHVNMTEzADSz9/fMGAHjHmKRxhIWFKT4+XiEhIdXW1fV7khkbAICAYbfbdfjwYVksFnXs2FEhISEXnPC3NIZh6LvvvtORI0fUs2fPgJu5YRiGx3N+5MgRRUZG+qBFAICWiDHJhTMMQ6Wlpfruu+90+PBh9ezZU2Zzw24DSrABAAgYpaWlstvtSkhIUFhYmK+bE7A6dOigr7/+WmVlZQETbAwaNEgmk0kmk0kjR45UUND5IUxFRYUOHz6s0aNH+7CFAICWhDFJ42jVqpWCg4P1zTffqLS0VKGhoQ3aD8EGACDgNDTNh0Mg/kVpwoQJkqS9e/cqOTnZ7TKakJAQde3aVRMnTvRR6wAALRVjkgvXGJ8hwQYAAPB7jz32mCSpa9euuvXWWxv8Fx0AAND8EGwAAICAMWXKFF83AQAA+BnmzQAAEGC6du2qZ5991tfNaDLR0dH6/vvvJUlt27ZVdHS01wUAADQdfxmTMGMDAIAmcM0112jgwIGN8uW/c+dOtW7d+sIbFSCWLl2qNm3aOF8H4j1CAADwF81xTEKwAQCAHzAMQxUVFW5P+/CmQ4cOTdAi/+F6+cldd93lu4YAANACBOKYhEtRAAAByzAMnS4t98liGEad23nXXXcpMzNTzz33nPORpStXrpTJZNJ7772nIUOGyGq16uOPP9ahQ4d00003KTY2VuHh4br88su1adMmt/1VnfZpMpn0hz/8QTfffLPCwsLUs2dP/f3vf2+sj9mvrFy50mN5eXm50tLSmrYxAAC4CIRxSXMdkzBjAwAQsM6UVSjx0Y0+OfbnC5MVFlK3r9HnnntOX375pfr166eFCxdKkvbv3y9Jevjhh/XUU0/p0ksvVdu2bZWbm6uxY8fq8ccfl9Vq1R//+EeNHz9eBw4cUOfOnb0eY8GCBXriiSf05JNP6n//9381efJkffPNN83uvhO/+tWvtH79er300ktq27atJOnAgQO6/fbbdezYMaWnp/u4hQCAlioQxiXNdUzCjA0AAC6yyMhIhYSEKCwsTHFxcYqLi5PFYpEkLVy4UNdff726d++u6OhoDRgwQPfdd5/69eunnj17atGiRerevXutf+246667NGnSJPXo0UOLFy9WcXGx/vWvfzVF95rUnj17dOTIEfXv318ZGRlatmyZBg8erN69e+vTTz/1dfMAAPBrzXVMwowNAEDAahVs0ecLk3127MYwdOhQt/fFxcWaP3++1q9fr6NHj6q8vFxnzpxRTk5OjftJSkpyvm7durUiIiJUUFDQKG30J927d9fWrVs1c+ZMjR49WhaLRa+//romTZrk66YBAFq4QB+XBPKYpEHBxuuvv6727dtr3LhxkqRf//rXeumll5SYmKg///nP6tKlS6M2EgAAT0wmU50vB/FXVe8kPmfOHGVkZOipp55Sjx491KpVK/30pz9VaWlpjfsJDg52e28ymWS32xu9vf5g/fr1Wr16tWw2m7788ku98soruvrqq9WxY0dfNw0A0IIF+rgkkMckDboUZfHixWrVqpUkKSsrS8uWLdMTTzyh9u3ba9asWQ1qyJIlS2QymTRz5kyvdSpvauK6hIaGNuh4AAA0pZCQEFVUVNRab+vWrbrrrrt08803q3///oqLi9PXX3998RsYIO677z797Gc/09y5c/XPf/5Tn332mUJCQtS/f3/99a9/9XXzAADwe81xTNKgOCk3N1c9evSQJL399tuaOHGi7r33Xl1xxRW65ppr6r2/nTt36sUXX3SbsuJNRESEDhw44HzPs+wBAIGga9eu2rFjh77++muFh4d7/ctFz5499dZbb2n8+PEymUx65JFHmu3Mi4bYunWrduzYoQEDBkiS4uLi9O6772rZsmW6++679fOf/9zHLQQAwL81xzFJg2ZshIeH69ixY5Kk999/X9dff70kKTQ0VGfOnKnXvoqLizV58mS9/PLLzrub18RkMjlvchIXF6fY2Nj6dwAAgCY2Z84cWSwWJSYmqkOHDl6vT33mmWfUtm1bjRgxQuPHj1dycrIGDx7cxK31X7t27XKGGq5SU1O1a9cuH7QIAIDA0hzHJA2asXH99dfrnnvu0aBBg/Tll19q7NixkhyPienatWu99pWamqpx48Zp1KhR+u1vf1tr/eLiYnXp0kV2u12DBw/W4sWL1bdvX6/1S0pKVFJS4nxfVFRUr/YBANAYLrvsMmVlZbmV3XXXXdXqde3aVR988IFbWWpqqtv7qtNAPT27/sSJEw1qp7+zWq06dOiQXnvtNR06dEjPPfecYmJi9N5779X46DkAAODQHMckDZqxsWzZMtlsNn333Xf629/+pnbt2kly/BWlPnclX716tXbv3l3nZ8736tVLr776qt555x396U9/kt1u14gRI3TkyBGv26SnpysyMtK5JCQk1Ll9AADAv2RmZqp///7asWOH3nrrLRUXF0uSPv30Uz322GM+bh0AAPCFBs3YiIqK0gsvvFCtfMGCBXXeR25urh544AFlZGTU+QagNptNNpvN+X7EiBHq06ePXnzxRS1atMjjNmlpaZo9e7bzfVFREeEGAAAB6uGHH9Zvf/tbzZ49W23atHGWX3fddR7HJgAAoPlr0IyNDRs26OOPP3a+X7ZsmQYOHKjbb79dx48fr9M+du3apYKCAg0ePFhBQUEKCgpSZmamnn/+eQUFBdXpLq3BwcEaNGiQDh486LWO1WpVRESE2wIAAAJTdna2br755mrlMTEx+v77733QIgAA4GsNCjYeeugh570qsrOz9eCDD2rs2LE6fPiw2+yImowcOVLZ2dnau3evcxk6dKgmT56svXv3ymKx1LqPiooKZWdnKz4+viHdAAAAASYqKkpHjx6tVr5nzx5dcsklPmgRAADwtQZdinL48GElJiZKkv72t7/pxhtv1OLFi7V7927njURr06ZNG/Xr18+trHXr1mrXrp2zPCUlRZdcconzHhwLFy7U8OHD1aNHD504cUJPPvmkvvnmG91zzz0N6QYAAAgwt912m+bOnas1a9bIZDLJbrdr69atmjNnjlJSUnzdPAAA4AMNmrEREhKi06dPS5I2bdqkG264QZIUHR3dqE8dycnJcfurzPHjxzVt2jT16dNHY8eOVVFRkbZt2+YMWQAAQPO2ePFi9e7dWwkJCSouLlZiYqKuuuoqjRgxQvPmzavzftLT03X55ZerTZs2iomJ0YQJE3TgwAG3OmfPnlVqaqratWun8PBwTZw4Ufn5+W51cnJyNG7cOIWFhSkmJkYPPfSQysvLG6WvAACgbho0Y+PKK6/U7NmzdcUVV+hf//qX/vKXv0iSvvzyS3Xq1KnBjdmyZUuN75cuXaqlS5c2eP8AACCwhYSE6OWXX9Yjjzyiffv2qbi4WIMGDVLPnj3rtZ/MzEylpqbq8ssvV3l5uX7zm9/ohhtu0Oeff67WrVtLkmbNmqX169drzZo1ioyM1IwZM3TLLbdo69atkhyXxI4bN05xcXHatm2bjh49qpSUFAUHB2vx4sWN3ncAAOBZg4KNF154Qf/v//0/vfnmm1q+fLnzmtb33ntPo0ePbtQGAgAAVNW5c2d17ty5wdtv2LDB7f3KlSsVExOjXbt26aqrrlJhYaFeeeUVrVq1Stddd50k6bXXXlOfPn20fft2DR8+XO+//74+//xzbdq0SbGxsRo4cKAWLVqkuXPnav78+QoJCbmgPgIAgLppULDRuXNnrVu3rlo5sykAALg4unbtqpkzZ2rmzJm+bkqTq+uNySXpmWeeadAxCgsLJTkuq5UcT28rKyvTqFGjnHV69+6tzp07KysrS8OHD1dWVpb69++v2NhYZ53k5GRNnz5d+/fv16BBg6odp6SkRCUlJc73jXkJLwAATcEfxyQNCjYkx/TLt99+W1988YUkqW/fvvrJT35Sp6eZAAAA1NWePXvqVM9kMjVo/3a7XTNnztQVV1zhvIF5Xl6eQkJCFBUV5VY3NjZWeXl5zjquoUbl+sp1nqSnp2vBggUNaicAAPCsQcHGwYMHNXbsWP33v/9Vr169JDm+qBMSErR+/Xp17969URsJAABarg8//PCi7j81NVX79u3Txx9/fFGPI0lpaWluM1CKioqUkJBw0Y8LAEBz1qCnovzqV79S9+7dlZubq927d2v37t3KyclRt27d9Ktf/aqx2wgAQEB76aWX1LFjR9ntdrfym266SXfffbcOHTqkm266SbGxsQoPD9fll1+uTZs2+ai1gSM3N1e5ubkXtI8ZM2Zo3bp1+vDDD91ugB4XF6fS0lKdOHHCrX5+fr7i4uKcdao+JaXyfWWdqqxWqyIiItwWAACaSnMdkzQo2MjMzNQTTzzhvA5Vktq1a6clS5YoMzOz0RoHAECNDEMqPeWbxTDq3Myf/exnOnbsmNvMgx9++EEbNmzQ5MmTVVxcrLFjx2rz5s3as2ePRo8erfHjxysnJ+difGoBrby8XI888ogiIyPVtWtXde3aVZGRkZo3b57KysrqvB/DMDRjxgytXbtWH3zwgbp16+a2fsiQIQoODtbmzZudZQcOHFBOTo5sNpskyWazKTs7WwUFBc46GRkZioiI4FH0ANASBcC4pLmOSRp0KYrVatXJkyerlRcXF3MHcABA0yk7LS3u6Jtj/+ZbKaR1naq2bdtWY8aM0apVqzRy5EhJ0ptvvqn27dvr2muvldls1oABA5z1Fy1apLVr1+rvf/+7ZsyYcVGaH6juv/9+vfXWW3riiSecAUNWVpbmz5+vY8eOafny5XXaT2pqqlatWqV33nlHbdq0cd4TIzIyUq1atVJkZKSmTp2q2bNnKzo6WhEREbr//vtls9k0fPhwSdINN9ygxMRE3XnnnXriiSeUl5enefPmKTU1VVar9eJ8AAAA/xUA45LmOiZp0IyNG2+8Uffee6927NghwzBkGIa2b9+uX/7yl/rJT37S2G0EACDgTZ48WX/729+cT8R44403dNttt8lsNqu4uFhz5sxRnz59FBUVpfDwcH3xxRd+/9cRX1i1apVWrlyp++67T0lJSUpKStJ9993nfDRrXS1fvlyFhYW65pprFB8f71z+8pe/OOssXbpUN954oyZOnKirrrpKcXFxeuutt5zrLRaL1q1bJ4vFIpvNpjvuuEMpKSlauHBho/YZAIDG1BzHJA2asfH8889rypQpstlsCg4OliSVlZXppptu0rPPPtuY7QMAwLvgMMdfKHx17HoYP368DMPQ+vXrdfnll+uf//yn8zHpc+bMUUZGhp566in16NFDrVq10k9/+lOVlpZejJYHNKvVqq5du1Yr79atW71mjRp1mLIbGhqqZcuWadmyZV7rdOnSRe+++26djwsAaMYCZFzSHMckDQo2oqKi9M477+jgwYPOx7326dNHPXr0aNTGAQBQI5OpzpeD+FpoaKhuueUWvfHGGzp48KB69eqlwYMHS5K2bt2qu+66SzfffLMkx6WdX3/9tQ9b679mzJihRYsW6bXXXnNe7lFSUqLHH3/cr6fIAgBagAAZlzTHMUmdgw3XR5N54nrzkWeeeabhLQIAoJmaPHmybrzxRu3fv1933HGHs7xnz5566623NH78eJlMJj3yyCPV7lYOhz179mjz5s3q1KmT8xrgTz/9VKWlpRo5cqRuueUWZ13Xy0YAAMB5zW1MUudgY8+ePXWqZzKZGtwYAACas+uuu07R0dE6cOCAbr/9dmf5M888o7vvvlsjRoxQ+/btNXfuXBUVFfmwpf4rKipKEydOdCtLSEjwUWsAAAhMzW1MYjLqcpFpM1JUVKTIyEgVFhby7HgACDBnz57V4cOH1a1bN4WGhvq6OQGrps/Rn78nDcNQbm6uOnTooFatWvm6OY3Cnz9vAIB3jEkaT2OMSxr0VBQAAICmZhiGevTooSNHjvi6KQAAwI8QbAAAgIBgNpvVs2dPHTt2zNdNAQAAfoRgAwAABIwlS5booYce0r59+3zdFAAA4Cca9LhXAAAAX0hJSdHp06c1YMAAhYSEVLvXxg8//OCjlgEAAF8h2AAAAAHj2Wef9XUTAACAnyHYAAAEnBb2QK9GF8if35QpU3zdBAAAnAL5O9VfNMZnyD02AAABIzg4WJJ0+vRpH7cksJWWlkqSLBaLj1vSMIcOHdK8efM0adIkFRQUSJLee+897d+/38ctAwC0FIxJGk/lZ1j5mTYEMzYAAAHDYrEoKirK+T+zYWFhMplMPm5VYLHb7fruu+8UFhamoKDAGwZkZmZqzJgxuuKKK/TRRx/p8ccfV0xMjD799FO98sorevPNN33dRABAC8CY5MIZhqHTp0+roKBAUVFRF/QHl8Ab0QAAWrS4uDhJcg4kUH9ms1mdO3cOyAHYww8/rN/+9reaPXu22rRp4yy/7rrr9MILL/iwZQCAloYxSeOIiopyfpYNRbABAAgoJpNJ8fHxiomJUVlZma+bE5BCQkJkNgfm1ajZ2dlatWpVtfKYmBh9//33PmgRAKClYkxy4YKDgxvl0liCDQBAQLJYLAF7jwg0XFRUlI4ePapu3bq5le/Zs0eXXHKJj1oFAGjJGJP4XmD+uQYAALRIt912m+bOnau8vDyZTCbZ7XZt3bpVc+bMUUpKiq+bBwAAfIBgAwAABIzFixerd+/eSkhIUHFxsRITE/XjH/9YI0aM0Lx583zdPAAA4ANcigIAAAJGSEiIXn75ZT366KPKzs7WqVOnNGjQIPXo0cPXTQMAAD5CsAEAAALKK6+8oqVLl+qrr76SJPXs2VMzZ87UPffc4+OWAQAAXyDYAAAAAePRRx/VM888o/vvv182m02SlJWVpVmzZiknJ0cLFy70cQsBAEBTI9gAAAABY/ny5Xr55Zc1adIkZ9lPfvITJSUl6f777yfYAACgBeLmoQAAIGCUlZVp6NCh1cqHDBmi8vJyH7QIAAD4GsEGAAAIGHfeeaeWL19erfyll17S5MmTfdAiAADga1yKAgAAAsorr7yi999/X8OHD5ck7dixQzk5OUpJSdHs2bOd9Z555hlfNREAADQhgg0AABAw9u3bp8GDB0uSDh06JElq37692rdvr3379jnrmUwmn7QPAAA0PYINAAAQMD788ENfNwEAAPgZv7nHxpIlS2QymTRz5swa661Zs0a9e/dWaGio+vfvr3fffbdpGggAAJqNjz76SOPHj1fHjh1lMpn09ttvu62/6667ZDKZ3JbRo0e71fnhhx80efJkRUREKCoqSlOnTlVxcXET9gIAAEh+Emzs3LlTL774opKSkmqst23bNk2aNElTp07Vnj17NGHCBE2YMMFt6ikAAEBtTp06pQEDBmjZsmVe64wePVpHjx51Ln/+85/d1k+ePFn79+9XRkaG1q1bp48++kj33nvvxW46AACowueXohQXF2vy5Ml6+eWX9dvf/rbGus8995xGjx6thx56SJK0aNEiZWRk6IUXXtCKFSuaorkAAKAZGDNmjMaMGVNjHavVqri4OI/rvvjiC23YsEE7d+50Pn72f//3fzV27Fg99dRT6tixY6O3GQAAeObzGRupqakaN26cRo0aVWvdrKysavWSk5OVlZXldZuSkhIVFRW5LQAAALXZsmWLYmJi1KtXL02fPl3Hjh1zrsvKylJUVJQz1JCkUaNGyWw2a8eOHb5oLgAALZZPZ2ysXr1au3fv1s6dO+tUPy8vT7GxsW5lsbGxysvL87pNenq6FixYcEHtBAAALcvo0aN1yy23qFu3bjp06JB+85vfaMyYMcrKypLFYlFeXp5iYmLctgkKClJ0dHSN45KSkhKVlJQ43/MHFwAALpzPgo3c3Fw98MADysjIUGho6EU7Tlpamtsz7YuKipSQkHDRjgcAAALfbbfd5nzdv39/JSUlqXv37tqyZYtGjhzZ4P3yBxcAABqfzy5F2bVrlwoKCjR48GAFBQUpKChImZmZev755xUUFKSKiopq28TFxSk/P9+tLD8/3+v1r5Lj+tiIiAi3BQAAoD4uvfRStW/fXgcPHpTkGJMUFBS41SkvL9cPP/xQ47gkLS1NhYWFziU3N/eithsAgJbAZ8HGyJEjlZ2drb179zqXoUOHavLkydq7d68sFku1bWw2mzZv3uxWlpGRIZvN1lTNBgAALdCRI0d07NgxxcfHS3KMSU6cOKFdu3Y563zwwQey2+0aNmyY1/3wBxcAABqfzy5FadOmjfr16+dW1rp1a7Vr185ZnpKSoksuuUTp6emSpAceeEBXX321nn76aY0bN06rV6/WJ598opdeeqnJ2w8AAAJXcXGxc/aFJB0+fFh79+5VdHS0oqOjtWDBAk2cOFFxcXE6dOiQfv3rX6tHjx5KTk6WJPXp00ejR4/WtGnTtGLFCpWVlWnGjBm67bbbeCIKAABNzOdPRalJTk6Ojh496nw/YsQIrVq1Si+99JIGDBigN998U2+//Xa1gAQAAKAmn3zyiQYNGqRBgwZJkmbPnq1Bgwbp0UcflcVi0Weffaaf/OQnuuyyyzR16lQNGTJE//znP2W1Wp37eOONN9S7d2+NHDlSY8eO1ZVXXskfWwAA8AGTYRiGrxvRlIqKihQZGanCwkKmfwIAUAXfk02LzxsAAO/q+j3p1zM2AAAAAAAAakKwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgIBFsAEAAAAAAAIWwQYAAAAAAAhYBBsAAAAAACBgEWwAAAAAAICARbABAAAAAAACFsEGAAAAAAAIWAQbAAAAAAAgYBFsAAAAAACAgEWwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgIBFsAEAAAAAAAIWwQYAAAAAAAhYBBsAAAAAACBgEWwAAAAAAICARbABAAAAAAACFsEGAAAAAAAIWAQbAAAAAAAgYBFsAAAAAACAgEWwAQAAAAAAAhbBBgAAAAAACFgEGwAAoMX56KOPNH78eHXs2FEmk0lvv/2223rDMPToo48qPj5erVq10qhRo/TVV1+51fnhhx80efJkRUREKCoqSlOnTlVxcXET9gIAAEgEGwAAoAU6deqUBgwYoGXLlnlc/8QTT+j555/XihUrtGPHDrVu3VrJyck6e/ass87kyZO1f/9+ZWRkaN26dfroo4907733NlUXAADAOSbDMAxfN6IpFRUVKTIyUoWFhYqIiPB1cwAA8Cst8XvSZDJp7dq1mjBhgiTHbI2OHTvqwQcf1Jw5cyRJhYWFio2N1cqVK3Xbbbfpiy++UGJionbu3KmhQ4dKkjZs2KCxY8fqyJEj6tixY52O3RI/bwAA6qqu35PM2AAAAHBx+PBh5eXladSoUc6yyMhIDRs2TFlZWZKkrKwsRUVFOUMNSRo1apTMZrN27Njhdd8lJSUqKipyWwAAwIUh2AAAAHCRl5cnSYqNjXUrj42Nda7Ly8tTTEyM2/qgoCBFR0c763iSnp6uyMhI55KQkNDIrQcAoOUh2AAAAGgiaWlpKiwsdC65ubm+bhIAAAGPYAMAAMBFXFycJCk/P9+tPD8/37kuLi5OBQUFbuvLy8v1ww8/OOt4YrVaFRER4bYAAIAL49NgY/ny5UpKSnJ+sdtsNr333nte669cuVImk8ltCQ0NbcIWAwCA5q5bt26Ki4vT5s2bnWVFRUXasWOHbDabJMlms+nEiRPatWuXs84HH3wgu92uYcOGNXmbAQBoyYJ8efBOnTppyZIl6tmzpwzD0Ouvv66bbrpJe/bsUd++fT1uExERoQMHDjjfm0ympmouAABoJoqLi3Xw4EHn+8OHD2vv3r2Kjo5W586dNXPmTP32t79Vz5491a1bNz3yyCPq2LGj88kpffr00ejRozVt2jStWLFCZWVlmjFjhm677bY6PxEFAAA0Dp8GG+PHj3d7//jjj2v58uXavn2712DDZDLVOMUTAACgNp988omuvfZa5/vZs2dLkqZMmaKVK1fq17/+tU6dOqV7771XJ06c0JVXXqkNGza4zRR94403NGPGDI0cOVJms1kTJ07U888/3+R9AQCgpfNpsOGqoqJCa9as0alTp5zTPD0pLi5Wly5dZLfbNXjwYC1evNhrCAIAAODJNddcI8MwvK43mUxauHChFi5c6LVOdHS0Vq1adTGaBwAA6sHnwUZ2drZsNpvOnj2r8PBwrV27VomJiR7r9urVS6+++qqSkpJUWFiop556SiNGjND+/fvVqVMnj9uUlJSopKTE+Z7nxQMAAAAA0Hz4/KkovXr10t69e7Vjxw5Nnz5dU6ZM0eeff+6xrs1mU0pKigYOHKirr75ab731ljp06KAXX3zR6/55XjwAAAAAAM2XyahpHqYPjBo1St27d68xrHD1s5/9TEFBQfrzn//scb2nGRsJCQkqLCzkEWsAAFRRVFSkyMhIviebCJ83AADe1fV70uczNqqy2+1uQURNKioqlJ2drfj4eK91eF48AAAAAADNl0/vsZGWlqYxY8aoc+fOOnnypFatWqUtW7Zo48aNkqSUlBRdcsklSk9PlyQtXLhQw4cPV48ePXTixAk9+eST+uabb3TPPff4shsAAAAAAMBHfBpsFBQUKCUlRUePHlVkZKSSkpK0ceNGXX/99ZKknJwcmc3nJ5UcP35c06ZNU15entq2bashQ4Zo27ZtXm82CgAAAAAAmje/u8fGxca1rAAAeMf3ZNPi8wYAwLuAvccGAAAAAABAXRFsAAAAAACAgEWwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgIBFsAEAAAAAAAIWwQYAAAAAAAhYBBsAAAAAACBgEWwAAAAAAICARbABAAAAAAACFsEGAAAAAAAIWAQbAAAAAAAgYBFsAAAAAACAgEWwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgIBFsAEAAAAAAAIWwQYAAIAH8+fPl8lkclt69+7tXH/27FmlpqaqXbt2Cg8P18SJE5Wfn+/DFgMA0DIRbAAAAHjRt29fHT161Ll8/PHHznWzZs3SP/7xD61Zs0aZmZn69ttvdcstt/iwtQAAtExBvm4AAACAvwoKClJcXFy18sLCQr3yyitatWqVrrvuOknSa6+9pj59+mj79u0aPnx4UzcVAIAWixkbAAAAXnz11Vfq2LGjLr30Uk2ePFk5OTmSpF27dqmsrEyjRo1y1u3du7c6d+6srKwsr/srKSlRUVGR2wIAAC4MwQYAAIAHw4YN08qVK7VhwwYtX75chw8f1o9//GOdPHlSeXl5CgkJUVRUlNs2sbGxysvL87rP9PR0RUZGOpeEhISL3AsAAJo/LkUBAADwYMyYMc7XSUlJGjZsmLp06aK//vWvatWqVYP2mZaWptmzZzvfFxUVEW4AAHCBmLEBAABQB1FRUbrssst08OBBxcXFqbS0VCdOnHCrk5+f7/GeHJWsVqsiIiLcFgAAcGEINgAAAOqguLhYhw4dUnx8vIYMGaLg4GBt3rzZuf7AgQPKycmRzWbzYSsBAGh5uBQFAADAgzlz5mj8+PHq0qWLvv32Wz322GOyWCyaNGmSIiMjNXXqVM2ePVvR0dGKiIjQ/fffL5vNxhNRAABoYgQbAAAAHhw5ckSTJk3SsWPH1KFDB1155ZXavn27OnToIElaunSpzGazJk6cqJKSEiUnJ+v3v/+9j1sNAEDLYzIMw/B1I5pSUVGRIiMjVVhYyHWtAABUwfdk0+LzBgDAu7p+T3KPDQAAAAAAELAINgAAAAAAQMAi2AAAAAAAAAGLYAMAAAAAAAQsgg0AAAAAABCwfBpsLF++XElJSYqIiFBERIRsNpvee++9GrdZs2aNevfurdDQUPXv31/vvvtuE7UWAAAAAAD4myBfHrxTp05asmSJevbsKcMw9Prrr+umm27Snj171Ldv32r1t23bpkmTJik9PV033nijVq1apQkTJmj37t3q16+fD3rg8Og7+1RWYcgaZJY1yKyQILNCLOd+BpllDbI4X4dYzO71XMuDLc7trOfKzGaTz/oFAAAAAIC/MxmGYfi6Ea6io6P15JNPaurUqdXW3XrrrTp16pTWrVvnLBs+fLgGDhyoFStW1Gn/F+N58YmPbtDp0opG2VdVwRaTW0hyPhyxuAQnlcGIe6ASYrG4lVmD3H+GWKrswyV4qRbKWMwKtphkMhG0AEBzdjG+J+EdnzcAAN7V9XvSpzM2XFVUVGjNmjU6deqUbDabxzpZWVmaPXu2W1lycrLefvttr/stKSlRSUmJ831RUVGjtNfVzFE9dabUrtKKCpWW2x1LhV0l5Y6l1HWpsKukvKJ6WZldJRWO967KKgyVVVTo1EUKTurDZJKCXWeceJqV4lbmHrx4mr3iWrdq4OI2q8V53PPbW5jNAgAAAAAtns+DjezsbNlsNp09e1bh4eFau3atEhMTPdbNy8tTbGysW1lsbKzy8vK87j89PV0LFixo1DZXde9V3RttX4ZhqKzCOBd2VKi04nwA4haUVLgGIxUqKTtfVlLu/tM1cCmpErycL3M/VmV5ud1waZuc6042Wo8bzmI2eZmpUj0ECbGYFXRu9kuQxaRgi/ncYlJQ5WuzScFBZgWZTQoJMivI7FhfWbf69o6fQWazQoJMjvpB5/ZT5TiEMAAAAABwcfg82OjVq5f27t2rwsJCvfnmm5oyZYoyMzO9hhv1lZaW5jbLo6ioSAkJCY2y74vBZDIpJMjxP9bhVp+fHtntRpUQpKJasOIWkFRUqec1SKmsW+E+q8VjOFPh3N71wqkKu6Ez9gqdKfP9bJbamE1SkMXsHoy4BClVg5ZaAxTX8qr1LGaFWDwHLSHn1tcY2JjNCnYeh8uPAAAAAPg3n/+fc0hIiHr06CFJGjJkiHbu3KnnnntOL774YrW6cXFxys/PdyvLz89XXFyc1/1brVZZrdbGbXQLYjabFGq2KDTY4uumyDAMlduNapfwlFZUD0dcZ7CUljsu8ymvsKuswn7u8h67ys/9dL6321VabqjcXr1eqXP7ym0cs1nKyu0qs7vXK6twD2Akye4y2yXQBFULRqoEMV4DFA8zY8xVwhe3/ZjO7cexbWX9INd9mk3OYKYyeAlyC3+qryeYAQAAAJo3nwcbVdntdrd7Yriy2WzavHmzZs6c6SzLyMjwek8ONC8mk8n5P7Ct/TyrqrC7BCCVYci5IKT2AOX8tmUVxrn6noKUKkFLle1LvRy7pm1cLz2qVG43VG6vkMp88EE2AkfYYaoWmLjOlglyDUpcgpqqAUtwtVDF5HbJkmuo4gh23GfYeAxrqoY05uphjcVMQAMAAAB449NgIy0tTWPGjFHnzp118uRJrVq1Slu2bNHGjRslSSkpKbrkkkuUnp4uSXrggQd09dVX6+mnn9a4ceO0evVqffLJJ3rppZd82Q2gGovZJIufzHSpj8p7vJTb7SorN1Rm9xyAOEOXGgKU0nPr6zpLxnVmTLnLLJgy+/n9ON5X7qf6dh5ymXPBjKGzCrzZMq5cAxNPgcj5e8N4mNVSQ1hzfjZM1TCm5rAmyCV4qRYOVdm/M1QioAEAAMBF4NNgo6CgQCkpKTp69KgiIyOVlJSkjRs36vrrr5ck5eTkyGw2O+uPGDFCq1at0rx58/Sb3/xGPXv21Ntvv61+/fr5qgtAs+K8x4vMUoivW1N/dvv54KMyBCmrMiOl8n3VUMXj+nPhjGugUu4W4BjVAhdv+y13C3Tcj1NW4bLeXv1SJun8E5ICdeZMJW8zaKqFIJbzQYyny4xc61beoLdqmcdtqgQ+3uq6BkbB1drmeG3mpsDwQ+9lH9WyLQdlkklmkySTSed+nPvpKDfJUVC5zmwynavj+Cm5ljm2c/502a6yvtnkuj9HXbPp/Gudq+soO7+d6dzKauVuxzpfZja7789xbPc6ch6/Sls97M/Zdrc+Vj2Wya2ua99Vtcytb+51K9sq17ZWPW6Vc1O9Xa79PLfe42dW+dm6H6/qvuRSr+p5cV1/fn/u+6psRtXfncr+e1rvev7c91/9s61pvWtO7vF3R9XbAqD5MhmGpyF088Xz4gH4u8pLmaoFIm4zVs6vL60WklQNTM5f1lR1vfOyJrtriONtu8pQxvW1h4Dm3PaeZtA0J5U3BQ72GKBUDUs8z6SpOVipS8jiOH6vuDa6tEN4o/SL78mm1dif95+2f6N5b+9rhJYBzY/X4KNK0OctdDkfJrmHSJJ78KJq23vep1u7qoZDVY7rLeiq3N51XU37lFs7vQdeXj8Pj8FSzfusLK0aulUL0mrY3vN5qHoOqgdsUtXP1PPnLG/7cPb7fFDnOZirXiaXbbyHhS77rmO/avzMPZzrGvvl5XN3buPl96y2fiX3jWu0QLGu35N+d48NAGjpKi9lCnSeZtB4msVSPTipEpZ4CWw8zpjxGtJ4n0XjLPdwmVNl3QoPKY3zpsCSJN8+nenhMb31y6sbJ9hAYLu2d4xeu+tyGTJkGI7fU8MwZEjnZoO5lJ977Vjn+B23G+fKXMqNanUd7+3n3jjLDOPcfs/vz7Wu634kx78Rrvur9ZjOY50vr2yv5N5Pu8c+V++DqtT1eHyX13aX/VXW9dpnu3sf5PZZOI4pl+O6fZZy7Zfn/Tu3c+m7XPvg2k/nZ1j9s3JbX+Uzc93X+X14PpbHttXQVl/8adX1s66ypukbAzRjh9PHNvkxCTYAABeF2WyS1WyRHzy5+oLZz92rpdYQxkvIUluwUufgxsv6+MhQX39E8BOXRLXSJVGtfN0MoM5cgypneCNvAU/VEMYlJKlav8r6yiDLWwhT2Q55Wa+qx/MQCFUNkVzbU3WfntpYWeoeMnkOouTtuC71z9c7H9LV5bg19d/jufBw/jyfj+plqtIO977WclzX7ap91rX3p9qxvXwGcutDzX1y7UPV47pu4/b7U0u/XENE9+NWOV7VftTQr+rnu+pncf54Hvvh8VyeL/PF5V/NYLgJAMDFZTabFGI+d/8ZAECjcZ0+f37yPQDUDyM0AAAAAAAQsAg2AAAAAABAwCLYAAAAAAAAAYtgAwAAAAAABCyCDQAAAAAAELAINgAAAAAAQMAi2AAAAAAAAAGLYAMAAOACLFu2TF27dlVoaKiGDRumf/3rX75uEgAALQrBBgAAQAP95S9/0ezZs/XYY49p9+7dGjBggJKTk1VQUODrpgEA0GIQbAAAADTQM888o2nTpukXv/iFEhMTtWLFCoWFhenVV1/1ddMAAGgxCDYAAAAaoLS0VLt27dKoUaOcZWazWaNGjVJWVpYPWwYAQMsS5OsGNDXDMCRJRUVFPm4JAAD+p/L7sfL7Et59//33qqioUGxsrFt5bGys/v3vf3vcpqSkRCUlJc73hYWFkhiXAADgSV3HJS0u2Dh58qQkKSEhwcctAQDAf508eVKRkZG+bkazk56ergULFlQrZ1wCAIB3tY1LWlyw0bFjR+Xm5qpNmzYymUyNss+ioiIlJCQoNzdXERERjbJPX6I//o3++Df649/oT+0Mw9DJkyfVsWPHRtlfc9a+fXtZLBbl5+e7lefn5ysuLs7jNmlpaZo9e7bzvd1u1w8//KB27doxLvGC/vg3+uPf6I9/oz+1q+u4pMUFG2azWZ06dboo+46IiGgWv5CV6I9/oz/+jf74N/pTM2Zq1E1ISIiGDBmizZs3a8KECZIcQcXmzZs1Y8YMj9tYrVZZrVa3sqioqIvSPn7P/Rv98W/0x7/RH//mi3FJiws2AAAAGsvs2bM1ZcoUDR06VD/60Y/07LPP6tSpU/rFL37h66YBANBiEGwAAAA00K233qrvvvtOjz76qPLy8jRw4EBt2LCh2g1FAQDAxUOw0QisVqsee+yxalNLAxX98W/0x7/RH/9Gf3AxzJgxw+ulJ77Q3H4v6I9/oz/+jf74N/rTeEwGz3MDAAAAAAAByuzrBgAAAAAAADQUwQYAAAAAAAhYBBsAAAAAACBgEWwAAAAAAICARbBRBx999JHGjx+vjh07ymQy6e233651my1btmjw4MGyWq3q0aOHVq5cedHbWVf17c+WLVtkMpmqLXl5eU3T4Bqkp6fr8ssvV5s2bRQTE6MJEybowIEDtW63Zs0a9e7dW6Ghoerfv7/efffdJmht7RrSn5UrV1Y7N6GhoU3U4potX75cSUlJioiIUEREhGw2m957770at/HXcyPVvz/+fG48WbJkiUwmk2bOnFljPX8+R67q0h9/P0fz58+v1r7evXvXuE2gnB80DGMS/x2TSIxLJP/+d5Vxif+eG08Yl/jXOfL3MQnBRh2cOnVKAwYM0LJly+pU//Dhwxo3bpyuvfZa7d27VzNnztQ999yjjRs3XuSW1k19+1PpwIEDOnr0qHOJiYm5SC2su8zMTKWmpmr79u3KyMhQWVmZbrjhBp06dcrrNtu2bdOkSZM0depU7dmzRxMmTNCECRO0b9++Jmy5Zw3pjyRFRES4nZtvvvmmiVpcs06dOmnJkiXatWuXPvnkE1133XW66aabtH//fo/1/fncSPXvj+S/56aqnTt36sUXX1RSUlKN9fz9HFWqa38k/z9Hffv2dWvfxx9/7LVuoJwfNBxjEgd/HJNIjEsq+eu/q4xL/PfcVMW4xD/PkV+PSQzUiyRj7dq1Ndb59a9/bfTt29et7NZbbzWSk5MvYssapi79+fDDDw1JxvHjx5ukTReioKDAkGRkZmZ6rfPzn//cGDdunFvZsGHDjPvuu+9iN6/e6tKf1157zYiMjGy6Rl2gtm3bGn/4wx88rgukc1Oppv4Eyrk5efKk0bNnTyMjI8O4+uqrjQceeMBr3UA4R/Xpj7+fo8cee8wYMGBAnesHwvlB42FM4v8Yl/g/xiX+h3FJZJO1rT78fUzCjI2LICsrS6NGjXIrS05OVlZWlo9a1DgGDhyo+Ph4XX/99dq6dauvm+NRYWGhJCk6OtprnUA6P3XpjyQVFxerS5cuSkhIqDWp95WKigqtXr1ap06dks1m81gnkM5NXfojBca5SU1N1bhx46p99p4EwjmqT38k/z9HX331lTp27KhLL71UkydPVk5Ojte6gXB+0LSa6+9EIIxJJMYl/vrvqsS4xJ/PDeMS/z1H/jwmCbooe23h8vLyFBsb61YWGxuroqIinTlzRq1atfJRyxomPj5eK1as0NChQ1VSUqI//OEPuuaaa7Rjxw4NHjzY181zstvtmjlzpq644gr169fPaz1v58dfrs+tVNf+9OrVS6+++qqSkpJUWFiop556SiNGjND+/fvVqVOnJmyxZ9nZ2bLZbDp79qzCw8O1du1aJSYmeqwbCOemPv3x93MjSatXr9bu3bu1c+fOOtX393NU3/74+zkaNmyYVq5cqV69euno0aNasGCBfvzjH2vfvn1q06ZNtfr+fn7Q9BiT+A7jEv/8d5Vxif+eG4lxiT+fI38fkxBsoFa9evVSr169nO9HjBihQ4cOaenSpfq///s/H7bMXWpqqvbt21fjtV6BpK79sdlsbsn8iBEj1KdPH7344otatGjRxW5mrXr16qW9e/eqsLBQb775pqZMmaLMzEyvX7r+rj798fdzk5ubqwceeEAZGRl+c2OqC9GQ/vj7ORozZozzdVJSkoYNG6YuXbror3/9q6ZOnerDlgG+EShjEolxSSV/+3eVcYn/nhvGJf59jvx9TEKwcRHExcUpPz/frSw/P18REREB95cRb370ox/51Rf1jBkztG7dOn300Ue1ppnezk9cXNzFbGK91Kc/VQUHB2vQoEE6ePDgRWpd/YSEhKhHjx6SpCFDhmjnzp167rnn9OKLL1arGwjnpj79qcrfzs2uXbtUUFDg9lfOiooKffTRR3rhhRdUUlIii8Xito0/n6OG9KcqfztHVUVFRemyyy7z2j5/Pj/wDcYkvsG45Dx/+3eVccl5/nZuGJdU52/nyJW/jUm4x8ZFYLPZtHnzZreyjIyMGq93CzR79+5VfHy8r5shwzA0Y8YMrV27Vh988IG6detW6zb+fH4a0p+qKioqlJ2d7RfnxxO73a6SkhKP6/z53HhTU3+q8rdzM3LkSGVnZ2vv3r3OZejQoZo8ebL27t3r8cvWn89RQ/pTlb+do6qKi4t16NAhr+3z5/MD32gJvxP+MiaRGJd44u//rjIu8Z9zw7ikOn87R678bkxyUW5J2sycPHnS2LNnj7Fnzx5DkvHMM88Ye/bsMb755hvDMAzj4YcfNu68805n/f/85z9GWFiY8dBDDxlffPGFsWzZMsNisRgbNmzwVRfc1Lc/S5cuNd5++23jq6++MrKzs40HHnjAMJvNxqZNm3zVBafp06cbkZGRxpYtW4yjR486l9OnTzvr3HnnncbDDz/sfL9161YjKCjIeOqpp4wvvvjCeOyxx4zg4GAjOzvbF11w05D+LFiwwNi4caNx6NAhY9euXcZtt91mhIaGGvv37/dFF9w8/PDDRmZmpnH48GHjs88+Mx5++GHDZDIZ77//vmEYgXVuDKP+/fHnc+NN1bt1B9o5qqq2/vj7OXrwwQeNLVu2GIcPHza2bt1qjBo1ymjfvr1RUFBgGEbgnx/UH2MS/x2TGAbjEsPw739XGZf477nxhnGJ/5wjfx+TEGzUQeWjxaouU6ZMMQzDMKZMmWJcffXV1bYZOHCgERISYlx66aXGa6+91uTt9qa+/fnd735ndO/e3QgNDTWio6ONa665xvjggw980/gqPPVDktvnffXVVzv7Vumvf/2rcdlllxkhISFG3759jfXr1zdtw71oSH9mzpxpdO7c2QgJCTFiY2ONsWPHGrt37276xntw9913G126dDFCQkKMDh06GCNHjnR+2RpGYJ0bw6h/f/z53HhT9Qs30M5RVbX1x9/P0a233mrEx8cbISEhxiWXXGLceuutxsGDB53rA/38oP4Yk/jvmMQwGJcYhn//u8q4xH/PjTeMS/znHPn7mMRkGIbR+PNAAAAAAAAALj7usQEAAAAAAAIWwQYAAAAAAAhYBBsAAAAAACBgEWwAAAAAAICARbABAAAAAAACFsEGAAAAAAAIWAQbAAAAAAAgYBFsAAhIW7Zskclk0okTJ3zdFAAA0IIxJgF8j2ADAAAAAAAELIINAAAAAAAQsAg2ADSI3W5Xenq6unXrplatWmnAgAF68803JZ2fkrl+/XolJSUpNDRUw4cP1759+9z28be//U19+/aV1WpV165d9fTTT7utLykp0dy5c5WQkCCr1aoePXrolVdecauza9cuDR06VGFhYRoxYoQOHDhwcTsOAAD8CmMSAAQbABokPT1df/zjH7VixQrt379fs2bN0h133KHMzExnnYceekhPP/20du7cqQ4dOmj8+PEqKyuT5Pjy//nPf67bbrtN2dnZmj9/vh555BGtXLnSuX1KSor+/Oc/6/nnn9cXX3yhF198UeHh4W7t+J//+R89/fTT+uSTTxQUFKS77767SfoPAAD8A2MSADIAoJ7Onj1rhIWFGdu2bXMrnzp1qjFp0iTjww8/NCQZq1evdq47duyY0apVK+Mvf/mLYRiGcfvttxvXX3+92/YPPfSQkZiYaBiGYRw4cMCQZGRkZHhsQ+UxNm3a5Cxbv369Ick4c+ZMo/QTAAD4N8YkAAzDMJixAaDeDh48qNOnT+v6669XeHi4c/njH/+oQ4cOOevZbDbn6+joaPXq1UtffPGFJOmLL77QFVdc4bbfK664Ql999ZUqKiq0d+9eWSwWXX311TW2JSkpyfk6Pj5eklRQUHDBfQQAAP6PMQkASQrydQMABJ7i4mJJ0vr163XJJZe4rbNarW4DiYZq1apVneoFBwc7X5tMJkmOa20BAEDzx5gEgMQ9NgA0QGJioqxWq3JyctSjRw+3JSEhwVlv+/btztfHjx/Xl19+qT59+kiS+vTpo61bt7rtd+vWrbrssstksVjUv39/2e12t+tjAQAAXDEmASAxYwNAA7Rp00Zz5szRrFmzZLfbdeWVV6qwsFBbt25VRESEunTpIklauHCh2rVrp9jYWP3P//yP2rdvrwkTJkiSHnzwQV1++eVatGiRbr31VmVlZemFF17Q73//e0lS165dNWXKFN199916/vnnNWDAAH3zzTcqKCjQz3/+c191HQAA+BHGJAAkcfNQAA1jt9uNZ5991ujVq5cRHBxsdOjQwUhOTjYyMzOdN9H6xz/+YfTt29cICQkxfvSjHxmffvqp2z7efPNNIzEx0QgODjY6d+5sPPnkk27rz5w5Y8yaNcuIj483QkJCjB49ehivvvqqYRjnb9R1/PhxZ/09e/YYkozDhw9f7O4DAAA/wZgEgMkwDMOXwQqA5mfLli269tprdfz4cUVFRfm6OQAAoIViTAK0DNxjAwAAAAAABCyCDQAAAAAAELC4FAUAAAAAAAQsZmwAAAAAAICARbABAAAAAAACFsEGAAAAAAAIWAQbAAAAAAAgYBFsAAAAAACAgEWwAQAAAAAAAhbBBgAAAAAACFgEGwAAAAAAIGARbAAAAAAAgID1/wEKSf7aiQcAFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1300x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Best validation loss: 5.863245010375977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.863245010375977"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "train_dataset = MyDataset(data_dir=\"data\", src_file=\"train.de-en.de\", trg_file=\"train.de-en.en\")\n",
    "val_dataset = MyDataset(data_dir=\"data\", src_file=\"val.de-en.de\", trg_file=\"val.de-en.en\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "train(transformer, optimizer, train_loader, val_loader, NUM_EPOCHS, DEVICE, PAD_IDX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(0)).to(DEVICE)\n",
    "        # print(ys.size(), memory.size(), tgt_mask.size())\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        # out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1, :])\n",
    "        # print(prob.shape)\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        # print(next_word)\n",
    "        _, next_word = torch.max(next_word, dim=0)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, loader):\n",
    "    model.eval()\n",
    "    translated = []\n",
    "    for src in tqdm(loader, \"Prediction\"):\n",
    "        num_tokens = src.shape[0]\n",
    "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "        tgt_tokens = greedy_decode(\n",
    "            model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "        translation = \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "        translated.append(translation)\n",
    "        print(translation)\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707a64568dd4472bb0b7837e85433a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prediction:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      " <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = MyDataset('data', 'test1.de-en.de')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=test_collate_fn)\n",
    "translations = translate(transformer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
